{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p> Samuel Wolfe <br> July 26, 2023 <br> MSBA 206 <br> DMBA Case 21.4 Part 2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from dmba import regressionSummary, classificationSummary, liftChart, gainsChart\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(url):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    return df\n",
    "def statslist(df):\n",
    "    dfStats = pd.DataFrame({'Mean' : df.mean(numeric_only=True),\n",
    "            'SD' : df.std(numeric_only=True),\n",
    "            'Min' : df.min(),\n",
    "            'Max' : df.max(),\n",
    "            'Median' : df.median(numeric_only=True),\n",
    "            })\n",
    "    return dfStats\n",
    "def categorize(df):\n",
    "    for x in df:\n",
    "        df[x] = df[x].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVote = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-206/main/dmba/Voter-Persuasion.csv\")\n",
    " #do not need these as they are duplicates of values or states as not useable\n",
    "dropCol = ['VOTER_ID','SET_NO','Partition','opposite','MOVED_AD']\n",
    "dfVote = dfVote.drop(columns=dropCol)\n",
    "outcome = 'MOVED_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dfVote.drop(columns=['MOVED_A','COMM_PT']), drop_first=True)\n",
    "predictors = X.columns.to_list()\n",
    "y = dfVote[outcome]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LassoCV().fit(X, y)\n",
    "importance = np.abs(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['CAND1S_S' 'ED_4COL' 'COMM_CAR' 'NH_WHITE' 'E_PELIG' 'COMM_LT10' 'AGE'\n",
      " 'PP_PELIG' 'M_MAR' 'HH_ND']\n"
     ]
    }
   ],
   "source": [
    "idx_third = importance.argsort()[-3]\n",
    "threshold = importance[idx_third] + 0.01\n",
    "\n",
    "idx_features = (-importance).argsort()[:10]\n",
    "name_features = np.array(predictors)[idx_features]\n",
    "print('Selected features: {}'.format(name_features))\n",
    "\n",
    "sfm = SelectFromModel(clf, threshold=threshold)\n",
    "sfm.fit(X, y)\n",
    "X_transform = sfm.transform(X)\n",
    "\n",
    "n_features = sfm.transform(X).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['CAND1S_S','ED_4COL','COMM_CAR','NH_WHITE','E_PELIG','COMM_LT10','AGE','PP_PELIG','M_MAR','HH_ND']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVote = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-206/main/dmba/Voter-Persuasion.csv\")\n",
    " #do not need these as they are duplicates of values or states as not useable\n",
    "dropCol = ['VOTER_ID','SET_NO','Partition','MOVED_AD','opposite']\n",
    "dfVoteDum = pd.get_dummies(dfVote.drop(columns=dropCol))\n",
    "dfVoteDum = dfVoteDum[predictors]\n",
    "outcome = 'MOVED_A'\n",
    "classes = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['ED_4COL'] = pd.qcut(dfVoteDum['ED_4COL'], q=10, labels=[0,1,2,3,4,5,6,7,8,9],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['COMM_CAR'] = pd.qcut(dfVoteDum['COMM_CAR'], q=5, labels=[0,1,2,3,4],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['M_MAR'] = pd.qcut(dfVoteDum['M_MAR'], q=5, labels=[0,1,2,3,4],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['AGE'] = pd.qcut(dfVoteDum['AGE'], q=3, labels=[0,1,2],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['COMM_LT10'] = pd.qcut(dfVoteDum['COMM_LT10'], q=4, labels=[0,1,2,3],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['E_PELIG'] = pd.qcut(dfVoteDum['E_PELIG'], q=4, labels=[0,1,2,3],  precision=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVoteDum['ED_4COL'] = pd.cut(x=dfVoteDum['ED_4COL'], bins=[-1,4,20], labels=[0,1],  precision=0)\n",
    "dfVoteDum['NH_WHITE'] = pd.qcut(dfVoteDum['NH_WHITE'], q=5, labels=[0,1,2,3,4],  precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all categories into category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVoteDum = categorize(dfVoteDum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Partition and MOVED_A back to dfVoteDum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVoteDum['Partition'] = dfVote['Partition']\n",
    "dfVoteDum['MOVED_A'] = dfVote['MOVED_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(dfVoteDum[predictors])\n",
    "X_dfVoteDum = scaler.transform(dfVoteDum.drop(columns=outcome).drop(columns='Partition'))\n",
    "Y_dfVoteDum = dfVoteDum[outcome]\n",
    "\n",
    "dfVote_T = dfVoteDum[dfVoteDum.Partition == 'T'].drop(columns='Partition')\n",
    "X_train = dfVote_T.drop(columns=outcome)\n",
    "Y_train = dfVote_T[outcome].to_frame()\n",
    "\n",
    "dfVote_V = dfVoteDum[dfVoteDum.Partition == 'V'].drop(columns='Partition')\n",
    "X_valid = dfVote_V.drop(columns=outcome)\n",
    "Y_valid = dfVote_V[outcome].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "# Transform the predictors of training, validation\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_valid_norm = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running full dataset knn ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k mean accuracy standard deviation\n",
      "9  19        82.81%              1.03%\n",
      "8  17        82.72%              1.04%\n",
      "7  15        82.62%              1.31%\n",
      "6  13        82.42%              1.21%\n",
      "5  11        82.37%              1.18%\n",
      "4   9        82.21%              1.31%\n",
      "3   7        82.01%              1.15%\n",
      "2   5        80.84%              1.37%\n",
      "1   3        79.46%              1.47%\n",
      "0   1        75.42%              1.17%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k in range(1,20,2):\n",
    "    kfold = KFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(estimator=knn,\n",
    "                             X=X_dfVoteDum, y=Y_dfVoteDum, cv=kfold)\n",
    "    results.append({\n",
    "        'k' : k,\n",
    "        'mean accuracy' : f'{scores.mean():.2%}' ,\n",
    "        'standard deviation' : f'{scores.std():.2%}'\n",
    "    })\n",
    "results = pd.DataFrame(results).sort_values(by=['mean accuracy'],ascending=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting knn == 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN == 19\n",
      "Confusion Matrix (Accuracy 0.8334)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2123  448\n",
      "     1  227 1254\n"
     ]
    }
   ],
   "source": [
    "knn19 = KNeighborsClassifier(n_neighbors=19).fit(X_train_norm, Y_train.MOVED_A)\n",
    "print('KNN == 19')\n",
    "classificationSummary(Y_valid, knn19.predict(X_valid_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for Naive Bayes\n",
    "#### verifying dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAND1S_S     category\n",
       "ED_4COL      category\n",
       "COMM_CAR     category\n",
       "NH_WHITE     category\n",
       "E_PELIG      category\n",
       "COMM_LT10    category\n",
       "AGE          category\n",
       "PP_PELIG     category\n",
       "M_MAR        category\n",
       "HH_ND        category\n",
       "Partition      object\n",
       "MOVED_A         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVoteDum.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### claiming new predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors = dfVoteDum.drop(columns=['Partition','MOVED_A']).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data by T and V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(dfVoteDum[predictors])\n",
    "X_dfVoteDum = dfVoteDum.drop(columns=outcome).drop(columns='Partition')\n",
    "\n",
    "Y_dfVoteDum = dfVoteDum[outcome]\n",
    "\n",
    "dfVote_T = dfVoteDum[dfVoteDum.Partition == 'T'].drop(columns='Partition')\n",
    "X_train = dfVote_T.drop(columns=outcome)\n",
    "Y_train = dfVote_T[outcome].to_frame()\n",
    "\n",
    "dfVote_V = dfVoteDum[dfVoteDum.Partition == 'V'].drop(columns='Partition')\n",
    "X_valid = dfVote_V.drop(columns=outcome)\n",
    "Y_valid = dfVote_V[outcome].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_nb = MultinomialNB(alpha=1)\n",
    "vote_nb.fit(X_train, Y_train.MOVED_A)\n",
    "\n",
    "# predict probabilities\n",
    "predProb_train = vote_nb.predict_proba(X_train)\n",
    "predProb_valid = vote_nb.predict_proba(X_valid)\n",
    "\n",
    "# predict class membership\n",
    "y_train_pred = vote_nb.predict(X_train)\n",
    "y_valid_pred = vote_nb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking probability of all predictors vs outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVED_A\n",
      "0    0.6212\n",
      "1    0.3788\n",
      "Name: count, dtype: float64\n",
      "\n",
      "CAND1S_S   False    True\n",
      "MOVED_A                 \n",
      "0         0.2087  0.7913\n",
      "1         0.8810  0.1190\n",
      "\n",
      "ED_4COL       0       1       2       3       4       5       6       7  \\\n",
      "MOVED_A                                                                   \n",
      "0        0.1494  0.0647  0.0996  0.1556  0.0774  0.0774  0.1069  0.0825   \n",
      "1        0.1372  0.0746  0.0706  0.1687  0.0502  0.0666  0.1305  0.0830   \n",
      "\n",
      "ED_4COL       8       9  \n",
      "MOVED_A                  \n",
      "0        0.1101  0.0763  \n",
      "1        0.1256  0.0932  \n",
      "\n",
      "COMM_CAR       0       1       2       3       4\n",
      "MOVED_A                                         \n",
      "0         0.2663  0.1088  0.2198  0.1978  0.2073\n",
      "1         0.3600  0.1061  0.1984  0.1585  0.1771\n",
      "\n",
      "NH_WHITE       0       1       2       3       4\n",
      "MOVED_A                                         \n",
      "0         0.1710  0.2536  0.1608  0.2533  0.1613\n",
      "1         0.2708  0.1975  0.1505  0.2326  0.1487\n",
      "\n",
      "E_PELIG       0       1       2       3\n",
      "MOVED_A                                \n",
      "0        0.3185  0.2070  0.2823  0.1922\n",
      "1        0.2441  0.2241  0.2987  0.2330\n",
      "\n",
      "COMM_LT10       0       1       2       3\n",
      "MOVED_A                                  \n",
      "0          0.2796  0.2449  0.2263  0.2493\n",
      "1          0.3054  0.2503  0.2219  0.2224\n",
      "\n",
      "AGE           0       1       2\n",
      "MOVED_A                        \n",
      "0        0.3245  0.3678  0.3077\n",
      "1        0.3746  0.2921  0.3333\n",
      "\n",
      "PP_PELIG       0      50     100\n",
      "MOVED_A                         \n",
      "0         0.7829  0.1583  0.0587\n",
      "1         0.7266  0.2730  0.0004\n",
      "\n",
      "M_MAR         0       1       2       3       4\n",
      "MOVED_A                                        \n",
      "0        0.2068  0.2138  0.1835  0.2135  0.1824\n",
      "1        0.2716  0.2170  0.1660  0.1877  0.1576\n",
      "\n",
      "HH_ND         0       1       2       3       4       5       6       7  \\\n",
      "MOVED_A                                                                   \n",
      "0        0.4858  0.2512  0.1670  0.0631  0.0208  0.0057  0.0038  0.0008   \n",
      "1        0.1860  0.3316  0.2676  0.1287  0.0581  0.0129  0.0067  0.0018   \n",
      "\n",
      "HH_ND         8       9  \n",
      "MOVED_A                  \n",
      "0        0.0005  0.0014  \n",
      "1        0.0013  0.0053  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.precision', 4)\n",
    "# probability of flight status\n",
    "print(dfVote_T[outcome].value_counts() / len(dfVote_T))\n",
    "print()\n",
    "\n",
    "for predictor in predictors:\n",
    "    # construct the frequency table\n",
    "    df = dfVote_T[[outcome, predictor]]\n",
    "    freqTable = df.pivot_table(index=outcome, columns=predictor, aggfunc=len)\n",
    "\n",
    "    # divide each row by the sum of the row to get conditional probabilities\n",
    "    propTable = freqTable.apply(lambda x: x / sum(x), axis=1)\n",
    "    print(propTable)\n",
    "    print()\n",
    "pd.reset_option('display.precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Set\n",
      "Confusion Matrix (Accuracy 0.7745)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 3184  511\n",
      "     1  830 1423\n",
      "\n",
      "Validation Data Set\n",
      "Confusion Matrix (Accuracy 0.7786)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2179  392\n",
      "     1  505  976\n"
     ]
    }
   ],
   "source": [
    "print('Test Data Set')\n",
    "classificationSummary(Y_train, y_train_pred, class_names=classes) \n",
    "print()\n",
    "print('Validation Data Set')\n",
    "classificationSummary(Y_valid, y_valid_pred, class_names=classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4800000000000075"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8334-0.7786)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.1.4\n",
    "#### Between the KNN model and the Naive Bayes method, the most accurate was KNN, by an improvement of 5.48%. While Knn appears to have the edge over Naive Bayes, I am inclined to pick Naive Bayes because with this type of dataset quick categorical results on hundreds of thousands of people means Naive Bayes may produce better results long term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual  predicted         0         1\n",
      "0       0          0  0.901653  0.098347\n",
      "8       1          1  0.389598  0.610402\n",
      "9       0          0  0.901066  0.098934\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.width', 250)\n",
    "df = pd.concat([pd.DataFrame({'actual': Y_valid.MOVED_A, 'predicted': y_valid_pred}),\n",
    "                pd.DataFrame(predProb_valid, index=Y_valid.index)], axis=1)\n",
    "print(df.head(3))\n",
    "pd.reset_option('display.width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will admit to resorting to redoing my 24.1.1-2 analysis using a newer method. I believe this effort has been put to good use though. My Naive Bayes model is able to predict accurately the first three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVED_A\n",
      "0    0.6345\n",
      "1    0.3655\n",
      "Name: count, dtype: float64\n",
      "\n",
      "CAND1S_S   False    True\n",
      "MOVED_A                 \n",
      "0         0.2096  0.7904\n",
      "1         0.8953  0.1047\n",
      "\n",
      "ED_4COL       0      1       2       3       4       5       6       7       8       9\n",
      "MOVED_A                                                                               \n",
      "0        0.1599  0.072  0.0910  0.1478  0.0615  0.0852  0.1081  0.0817  0.1109  0.0821\n",
      "1        0.1404  0.077  0.0756  0.1789  0.0466  0.0722  0.1290  0.0905  0.1107  0.0790\n",
      "\n",
      "COMM_CAR       0       1       2       3       4\n",
      "MOVED_A                                         \n",
      "0         0.2657  0.0941  0.2415  0.2011  0.1976\n",
      "1         0.3801  0.1040  0.1783  0.1729  0.1648\n",
      "\n",
      "NH_WHITE       0       1       2       3       4\n",
      "MOVED_A                                         \n",
      "0         0.1816  0.2509  0.1641  0.2419  0.1614\n",
      "1         0.2924  0.1904  0.1506  0.2384  0.1283\n",
      "\n",
      "E_PELIG      0       1       2       3\n",
      "MOVED_A                               \n",
      "0        0.352  0.2096  0.2590  0.1793\n",
      "1        0.233  0.2188  0.3038  0.2444\n",
      "\n",
      "COMM_LT10       0       1       2       3\n",
      "MOVED_A                                  \n",
      "0          0.2991  0.2240  0.2030  0.2738\n",
      "1          0.3430  0.2411  0.2059  0.2100\n",
      "\n",
      "AGE           0       1       2\n",
      "MOVED_A                        \n",
      "0        0.3256  0.3633  0.3112\n",
      "1        0.3714  0.2964  0.3322\n",
      "\n",
      "PP_PELIG       0      50     100\n",
      "MOVED_A                         \n",
      "0         0.7923  0.1556  0.0521\n",
      "1         0.6989  0.3005  0.0007\n",
      "\n",
      "M_MAR         0       1       2       3       4\n",
      "MOVED_A                                        \n",
      "0        0.2252  0.1991  0.1754  0.2034  0.1968\n",
      "1        0.2802  0.2174  0.1634  0.1904  0.1485\n",
      "\n",
      "HH_ND         0       1       2       3       4       5       6       7       8       9\n",
      "MOVED_A                                                                                \n",
      "0        0.4675  0.2649  0.1673  0.0576  0.0261  0.0097  0.0035  0.0004  0.0004  0.0027\n",
      "1        0.1830  0.3322  0.2741  0.1310  0.0554  0.0142  0.0047  0.0020  0.0007  0.0027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.width', 250)\n",
    "pd.set_option('display.precision', 4)\n",
    "# probability of flight status\n",
    "print(dfVote_V['MOVED_A'].value_counts() / len(dfVote_V))\n",
    "print()\n",
    "\n",
    "for predictor in predictors:\n",
    "    # construct the frequency table\n",
    "    df = dfVote_V[['MOVED_A', predictor]]\n",
    "    freqTable = df.pivot_table(index='MOVED_A', columns=predictor, aggfunc=len)\n",
    "\n",
    "    # divide each row by the sum of the row to get conditional probabilities\n",
    "    propTable = freqTable.apply(lambda x: x / sum(x), axis=1)\n",
    "    print(propTable)\n",
    "    print()\n",
    "pd.reset_option('display.precision')\n",
    "pd.reset_option('display.width')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

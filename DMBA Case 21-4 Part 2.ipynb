{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <p> Samuel Wolfe <br> July 26, 2023 <br> MSBA 206 <br> DMBA Case 21.4 Part 2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from dmba import regressionSummary, classificationSummary, liftChart, gainsChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(url):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    return df\n",
    "def statslist(df):\n",
    "    dfStats = pd.DataFrame({'Mean' : df.mean(numeric_only=True),\n",
    "            'SD' : df.std(numeric_only=True),\n",
    "            'Min' : df.min(),\n",
    "            'Max' : df.max(),\n",
    "            'Median' : df.median(numeric_only=True),\n",
    "            })\n",
    "    return dfStats\n",
    "def categorize(df):\n",
    "    for x in df:\n",
    "        df[x] = df[x].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing in the predictors from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['PARTY_D', 'HH_ND', 'GENDER_F', 'COMM_PT', 'VPP_08', 'VPR_08', 'H_F1', 'PARTY_R', 'VPP_12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVote = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-206/main/dmba/Voter-Persuasion.csv\")\n",
    " #do not need these as they are duplicates of values or states as not useable\n",
    "dropCol = ['VOTER_ID','SET_NO','Partition','MOVED_AD','opposite']\n",
    "dfVoteDum = pd.get_dummies(dfVote.drop(columns=dropCol))\n",
    "dfVoteDum = dfVoteDum[predictors]\n",
    "outcome = 'MOVED_A'\n",
    "classes = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning COMM_PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVoteDum['COMM_PT'] = pd.qcut(dfVoteDum['COMM_PT'], q=4, labels=[0,1,2,3],  precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all categories into category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVoteDum = categorize(dfVoteDum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Partition and MOVED_A back to dfVoteDum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVoteDum['Partition'] = dfVote['Partition']\n",
    "dfVoteDum['MOVED_A'] = dfVote['MOVED_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(dfVoteDum[predictors])\n",
    "X_dfVoteDum = scaler.transform(dfVoteDum.drop(columns=outcome).drop(columns='Partition'))\n",
    "Y_dfVoteDum = dfVoteDum[outcome]\n",
    "\n",
    "dfVote_T = dfVoteDum[dfVoteDum.Partition == 'T'].drop(columns='Partition')\n",
    "X_train = dfVote_T.drop(columns=outcome)\n",
    "Y_train = dfVote_T[outcome].to_frame()\n",
    "\n",
    "dfVote_V = dfVoteDum[dfVoteDum.Partition == 'V'].drop(columns='Partition')\n",
    "X_valid = dfVote_V.drop(columns=outcome)\n",
    "Y_valid = dfVote_V[outcome].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "# Transform the predictors of training, validation\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_valid_norm = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running full dataset knn ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k mean accuracy standard deviation\n",
      "19  39        70.06%              1.80%\n",
      "12  25        70.00%              1.80%\n",
      "17  35        69.98%              1.46%\n",
      "18  37        69.96%              1.59%\n",
      "10  21        69.89%              1.52%\n",
      "16  33        69.85%              1.55%\n",
      "11  23        69.84%              1.82%\n",
      "13  27        69.77%              1.52%\n",
      "15  31        69.76%              1.68%\n",
      "14  29        69.66%              1.71%\n",
      "6   13        69.59%              2.01%\n",
      "7   15        69.50%              1.55%\n",
      "9   19        69.49%              1.59%\n",
      "8   17        69.36%              1.48%\n",
      "4    9        68.48%              1.82%\n",
      "5   11        68.32%              2.04%\n",
      "3    7        68.15%              2.09%\n",
      "2    5        67.14%              1.38%\n",
      "1    3        66.58%              1.54%\n",
      "0    1        66.19%              2.08%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for k in range(1,40,2):\n",
    "    kfold = KFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(estimator=knn,\n",
    "                             X=X_dfVoteDum, y=Y_dfVoteDum, cv=kfold)\n",
    "    results.append({\n",
    "        'k' : k,\n",
    "        'mean accuracy' : f'{scores.mean():.2%}' ,\n",
    "        'standard deviation' : f'{scores.std():.2%}'\n",
    "    })\n",
    "results = pd.DataFrame(results).sort_values(by=['mean accuracy'],ascending=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting knn == 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN == 13\n",
      "Confusion Matrix (Accuracy 0.6898)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1859  712\n",
      "     1  545  936\n"
     ]
    }
   ],
   "source": [
    "knn13 = KNeighborsClassifier(n_neighbors=13).fit(X_train_norm, Y_train.MOVED_A)\n",
    "print('KNN == 13')\n",
    "classificationSummary(Y_valid, knn13.predict(X_valid_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for Naive Bayes\n",
    "#### verifying dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARTY_D      category\n",
       "HH_ND        category\n",
       "GENDER_F     category\n",
       "COMM_PT      category\n",
       "VPP_08       category\n",
       "VPR_08       category\n",
       "H_F1         category\n",
       "PARTY_R      category\n",
       "VPP_12       category\n",
       "Partition      object\n",
       "MOVED_A         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVoteDum.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### claiming new predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = dfVoteDum.drop(columns=['Partition','MOVED_A']).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data by T and V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(dfVoteDum[predictors])\n",
    "#X_dfVoteDum = scaler.transform(dfVoteDum.drop(columns=outcome).drop(columns='Partition'))\n",
    "X_dfVoteDum = dfVoteDum.drop(columns=outcome).drop(columns='Partition')\n",
    "\n",
    "Y_dfVoteDum = dfVoteDum[outcome]\n",
    "\n",
    "dfVote_T = dfVoteDum[dfVoteDum.Partition == 'T'].drop(columns='Partition')\n",
    "X_train = dfVote_T.drop(columns=outcome)\n",
    "Y_train = dfVote_T[outcome].to_frame()\n",
    "\n",
    "dfVote_V = dfVoteDum[dfVoteDum.Partition == 'V'].drop(columns='Partition')\n",
    "X_valid = dfVote_V.drop(columns=outcome)\n",
    "Y_valid = dfVote_V[outcome].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_nb = MultinomialNB(alpha=1)\n",
    "vote_nb.fit(X_train, Y_train.MOVED_A)\n",
    "\n",
    "# predict probabilities\n",
    "predProb_train = vote_nb.predict_proba(X_train)\n",
    "predProb_valid = vote_nb.predict_proba(X_valid)\n",
    "\n",
    "# predict class membership\n",
    "y_train_pred = vote_nb.predict(X_train)\n",
    "y_valid_pred = vote_nb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking probability of all predictors vs outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVED_A\n",
      "0    0.6212\n",
      "1    0.3788\n",
      "Name: count, dtype: float64\n",
      "\n",
      "PARTY_D       0       1\n",
      "MOVED_A                \n",
      "0        0.6620  0.3380\n",
      "1        0.3076  0.6924\n",
      "\n",
      "HH_ND         0       1       2       3       4       5       6       7  \\\n",
      "MOVED_A                                                                   \n",
      "0        0.4858  0.2512  0.1670  0.0631  0.0208  0.0057  0.0038  0.0008   \n",
      "1        0.1860  0.3316  0.2676  0.1287  0.0581  0.0129  0.0067  0.0018   \n",
      "\n",
      "HH_ND         8       9  \n",
      "MOVED_A                  \n",
      "0        0.0005  0.0014  \n",
      "1        0.0013  0.0053  \n",
      "\n",
      "GENDER_F       0       1\n",
      "MOVED_A                 \n",
      "0         0.4853  0.5147\n",
      "1         0.3249  0.6751\n",
      "\n",
      "COMM_PT       0       1       2       3\n",
      "MOVED_A                                \n",
      "0        0.4357  0.1602  0.2382  0.1659\n",
      "1        0.3395  0.1429  0.2366  0.2810\n",
      "\n",
      "VPP_08        0       1\n",
      "MOVED_A                \n",
      "0        0.8135  0.1865\n",
      "1        0.7270  0.2730\n",
      "\n",
      "VPR_08        0       1\n",
      "MOVED_A                \n",
      "0        0.8701  0.1299\n",
      "1        0.7870  0.2130\n",
      "\n",
      "H_F1          0       1\n",
      "MOVED_A                \n",
      "0        0.9091  0.0909\n",
      "1        0.8411  0.1589\n",
      "\n",
      "PARTY_R       0       1\n",
      "MOVED_A                \n",
      "0        0.5719  0.4281\n",
      "1        0.9507  0.0493\n",
      "\n",
      "VPP_12        0       1\n",
      "MOVED_A                \n",
      "0        0.9177  0.0823\n",
      "1        0.9991  0.0009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.precision', 4)\n",
    "# probability of flight status\n",
    "print(dfVote_T[outcome].value_counts() / len(dfVote_T))\n",
    "print()\n",
    "\n",
    "for predictor in predictors:\n",
    "    # construct the frequency table\n",
    "    df = dfVote_T[[outcome, predictor]]\n",
    "    freqTable = df.pivot_table(index=outcome, columns=predictor, aggfunc=len)\n",
    "\n",
    "    # divide each row by the sum of the row to get conditional probabilities\n",
    "    propTable = freqTable.apply(lambda x: x / sum(x), axis=1)\n",
    "    print(propTable)\n",
    "    print()\n",
    "pd.reset_option('display.precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Set\n",
      "Confusion Matrix (Accuracy 0.6742)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 2398 1297\n",
      "     1  641 1612\n",
      "\n",
      "Validation Data Set\n",
      "Confusion Matrix (Accuracy 0.6693)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1640  931\n",
      "     1  409 1072\n"
     ]
    }
   ],
   "source": [
    "print('Test Data Set')\n",
    "classificationSummary(Y_train, y_train_pred, class_names=classes) \n",
    "print()\n",
    "print('Validation Data Set')\n",
    "classificationSummary(Y_valid, y_valid_pred, class_names=classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.1.4\n",
    "#### Between the KNN model and the Naive Bayes method, the most accurate was KNN, by an improvement of 2.05%. I specifically chose KNN 13 because of the cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
